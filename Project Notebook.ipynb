{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wux8AVk6KeTC"
      },
      "source": [
        "Project Title: Speech Emotion Recognition with Audio.\n",
        "\n",
        "Goal: Predicting Emotion from an audio file with speech.\n",
        "\n",
        ">Steps:\n",
        "1. Importing Necessary Packages\n",
        "2. As the data is stored on the drive a pipeline through drive and notebook is established with google.colab library for further processing.\n",
        "3. Data Cleaning and Manipulation.\n",
        "4. EDA on Audio files and content in the Audio files.\n",
        "5. Extract features from the audio files through python Librosa package.\n",
        "6. Initalize different Classifiers and Neural Network models from sci-kit and tensorflow libraries.\n",
        "7. Train the models.\n",
        "8. Test and Validate the models.\n",
        "9. Prerfomance Analysis of the models.\n",
        "10. Conclusion.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JOwm2CjZmw0i",
        "outputId": "0ad43eb6-030b-4821-c1e2-a4a9585cac1c"
      },
      "outputs": [],
      "source": [
        "# Importing all the required packages\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import IPython\n",
        "import tensorflow.keras.layers as L\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "from keras.utils import np_utils\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
        "import re\n",
        "import itertools\n",
        "%matplotlib inline\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "from sklearn.svm import SVC\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.graph_objects as go\n",
        "import plotly.express as px\n",
        "import plotly.figure_factory as ff\n",
        "import seaborn as sns\n",
        "import IPython\n",
        "import joblib\n",
        "import math\n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "94A53_Obmno8"
      },
      "outputs": [],
      "source": [
        "# Paths of different datasets\n",
        "Crema_Path = r'/Dataset/Crema'\n",
        "Ravdess_Path=r'/Dataset/Ravdess/audio_speech_actors_01-24'\n",
        "Savee_Path=r'/Dataset/Savee'\n",
        "Tess_Path=r'/Dataset/Tess'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "fKT9WimInhUD",
        "outputId": "9028f15b-7750-487a-94cd-2a8a8192a585"
      },
      "outputs": [],
      "source": [
        "# Creating a list for crema with emotion and audio file path\n",
        "crema=[]\n",
        "for wav in os.listdir(Crema_Path):\n",
        "    emotion=wav.partition(\".wav\")[0].split('_')\n",
        "    if emotion[2]=='SAD':\n",
        "        crema.append(('sad',Crema_Path+'/'+wav))\n",
        "    elif emotion[2]=='ANG':\n",
        "        crema.append(('angry',Crema_Path+'/'+wav))\n",
        "    elif emotion[2]=='DIS':\n",
        "        crema.append(('disgust',Crema_Path+'/'+wav))\n",
        "    elif emotion[2]=='FEA':\n",
        "        crema.append(('fear',Crema_Path+'/'+wav))\n",
        "    elif emotion[2]=='HAP':\n",
        "        crema.append(('happy',Crema_Path+'/'+wav))\n",
        "    elif emotion[2]=='NEU':\n",
        "        crema.append(('neutral',Crema_Path+'/'+wav))\n",
        "    else:\n",
        "        crema.append(('unknown',Crema_Path+'/'+wav))\n",
        "Crema_df=pd.DataFrame.from_dict(crema)\n",
        "Crema_df.rename(columns={0:'Emotion',1:'File_Path'},inplace=True)\n",
        "Crema_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3AaWbalsPkgP",
        "outputId": "082f6e1a-82ed-498e-866d-05e69b7fdd79"
      },
      "outputs": [],
      "source": [
        "# Unique Emotions in Crema\n",
        "Crema_df['Emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDe3RGZiPsnC",
        "outputId": "af8fafc1-194c-489b-8a0e-fc893256eb78"
      },
      "outputs": [],
      "source": [
        "# Crema data shape\n",
        "Crema_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "2u-8TbiVoe9u",
        "outputId": "88f2a2fb-531e-45e6-f3af-917f4e1b01fc"
      },
      "outputs": [],
      "source": [
        "# Emotion Distribution\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Emotions Counts of Crema')\n",
        "emotions=sns.countplot(x='Emotion',data=Crema_df,palette='Set3')\n",
        "emotions.set_xticklabels(emotions.get_xticklabels())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpmsKNBnfKHM",
        "outputId": "88e80748-fa57-4144-93c9-e86384306096"
      },
      "outputs": [],
      "source": [
        "# Null values if any,\n",
        "print('Number of null Values in crema data set: ',Crema_df.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fMcVakmNfb7x",
        "outputId": "4ef8b27c-c515-4e82-b1ff-abc39f89a987"
      },
      "outputs": [],
      "source": [
        "# Dataframe information\n",
        "Crema_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "euGpDSxhMVJe",
        "outputId": "425b0e75-1884-4a1e-cde6-a5860739ca04"
      },
      "outputs": [],
      "source": [
        "# Creating a list for ravdess with emotion and audio file path\n",
        "ravdess=[]\n",
        "for directory in os.listdir(Ravdess_Path):\n",
        "    actors=os.listdir(os.path.join(Ravdess_Path,directory))\n",
        "    for wav in actors:\n",
        "        emotion=wav.partition('.wav')[0].split('-')\n",
        "        emotion_number=int(emotion[2])\n",
        "        ravdess.append((emotion_number,os.path.join(Ravdess_Path,directory,wav)))\n",
        "Ravdess_df=pd.DataFrame.from_dict(ravdess)\n",
        "Ravdess_df.rename(columns={0:'Emotion',1:'File_Path'},inplace=True)\n",
        "Ravdess_df['Emotion'].replace({1:'neutral', 2:'neutral', 3:'happy', 4:'sad', 5:'angry', 6:'fear', 7:'disgust', 8:'surprise'},inplace=True)\n",
        "Ravdess_df.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4h4tKIeMMWbD",
        "outputId": "03c5f4f7-c6f2-4aac-e94f-28e94f8332e2"
      },
      "outputs": [],
      "source": [
        "# Unique Emotions in Ravdess\n",
        "Ravdess_df['Emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v8v16ybVMZRP",
        "outputId": "39789476-bebe-41eb-e401-1f0f2c0889f1"
      },
      "outputs": [],
      "source": [
        "# Ravdess file path size\n",
        "Ravdess_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "4strtsRMpbFS",
        "outputId": "3bad345b-a20d-41c2-9c5b-50fba99250c1"
      },
      "outputs": [],
      "source": [
        "# Emotion Distribution\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Emotions Counts in Ravdess')\n",
        "emotions=sns.countplot(x='Emotion',data=Ravdess_df,palette='Set3')\n",
        "emotions.set_xticklabels(emotions.get_xticklabels())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SdqOi08kfk-S",
        "outputId": "a27b230d-101f-4eb2-9ea2-0c6a39165e5b"
      },
      "outputs": [],
      "source": [
        "# Null values if any,\n",
        "print('Number of null Values in Ravdess data set: ',Ravdess_df.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l38FqNCBfqqT",
        "outputId": "4341f6ea-313f-4282-d312-5e260e2087b8"
      },
      "outputs": [],
      "source": [
        "# Dataframe information\n",
        "Ravdess_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Mdauhqe8MczA",
        "outputId": "537efa4f-f957-4823-ec36-41cfbafb8335"
      },
      "outputs": [],
      "source": [
        "# Creating a list for Savee with emotion and audio file path\n",
        "savee=[]\n",
        "for wav in os.listdir(Savee_Path):\n",
        "    emo=wav.partition('.wav')[0].split('_')[1].replace(r'[0-9]','')\n",
        "    emotion=re.split(r'[0-9]',emo)[0]\n",
        "    if emotion=='a':\n",
        "        savee.append(('angry',Savee_Path+'/'+wav))\n",
        "    elif emotion=='d':\n",
        "        savee.append(('disgust',Savee_Path+'/'+wav))\n",
        "    elif emotion=='f':\n",
        "        savee.append(('fear',Savee_Path+'/'+wav))\n",
        "    elif emotion=='h':\n",
        "        savee.append(('happy',Savee_Path+'/'+wav))\n",
        "    elif emotion=='n':\n",
        "        savee.append(('neutral',Savee_Path+'/'+wav))\n",
        "    elif emotion=='sa':\n",
        "        savee.append(('sad',Savee_Path+'/'+wav))\n",
        "    elif emotion=='su':\n",
        "        savee.append(('surprise',Savee_Path+'/'+wav))\n",
        "Savee_df=pd.DataFrame.from_dict(savee)\n",
        "Savee_df.rename(columns={0:'Emotion',1:'File_Path'},inplace=True)\n",
        "Savee_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HgEekBgNMh9_",
        "outputId": "13125d7c-5a4e-4f0f-beca-7e4a855b1c2f"
      },
      "outputs": [],
      "source": [
        "# Unique Emotions in Savee\n",
        "Savee_df['Emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnkQUPt1Mj7e",
        "outputId": "3449e1e6-49c7-4ef2-b0b1-419874d9a4bd"
      },
      "outputs": [],
      "source": [
        "#Savee list shape\n",
        "Savee_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "OzF49thKs2lQ",
        "outputId": "36719345-7b7a-4e6b-e201-1d9f63e2c9f5"
      },
      "outputs": [],
      "source": [
        "# Emotion Distribution\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Emotions Counts in Savee dataset')\n",
        "emotions=sns.countplot(x='Emotion',data=Savee_df,palette='Set3')\n",
        "emotions.set_xticklabels(emotions.get_xticklabels())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0UtdNa5y68s",
        "outputId": "209c9198-7d31-4d59-c643-56fb97ff8b15"
      },
      "outputs": [],
      "source": [
        "# Null values if any,\n",
        "print('Number of null Values in Savee data set: ',Savee_df.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFazS8Dnf0dS",
        "outputId": "7f936586-0883-45eb-92f7-ead78a6afcb9"
      },
      "outputs": [],
      "source": [
        "# Dataframe information\n",
        "Savee_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "YEj2QfrYMnoP",
        "outputId": "00582c5d-a51f-49f0-c98b-3592f47bb463"
      },
      "outputs": [],
      "source": [
        "# Creating a list for tess with emotion and audio file path\n",
        "tess=[]\n",
        "for directory in os.listdir(Tess_Path):\n",
        "    for wav in os.listdir(os.path.join(Tess_Path,directory)):\n",
        "        emotion=wav.partition('.wav')[0].split('_')\n",
        "        if emotion[2]=='ps':\n",
        "            tess.append(('surprise',os.path.join(Tess_Path,directory,wav)))\n",
        "        else:\n",
        "            tess.append((emotion[2],os.path.join(Tess_Path,directory,wav)))\n",
        "Tess_df=pd.DataFrame.from_dict(tess)\n",
        "Tess_df.rename(columns={0:'Emotion',1:'File_Path'},inplace=True)\n",
        "Tess_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcttA5r7Mtgc"
      },
      "outputs": [],
      "source": [
        "#Data corrections\n",
        "Tess_df.loc[Tess_df[\"Emotion\"] == 'neutral (1)'] = 'neutral'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2cs4bW7gOJJV",
        "outputId": "40baa835-833f-4e1d-c14a-0f198695a06a"
      },
      "outputs": [],
      "source": [
        "# Unique Emotions in tess\n",
        "Tess_df['Emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0eqc39kBMzP9",
        "outputId": "79f43ba5-f0b5-459d-9189-deae21061bdc"
      },
      "outputs": [],
      "source": [
        "# Tess data file shape\n",
        "Tess_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "id": "XzxTgsaDs5-g",
        "outputId": "2a90c97e-fa8e-49ba-da06-b0140e575065"
      },
      "outputs": [],
      "source": [
        "# Emotion Distribution\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Emotions Counts in Tess dataset')\n",
        "emotions=sns.countplot(x='Emotion',data=Tess_df,palette='Set3')\n",
        "emotions.set_xticklabels(emotions.get_xticklabels())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4aiq4f4y-Vg",
        "outputId": "d178dbe2-871a-4b87-a711-1107008e127d"
      },
      "outputs": [],
      "source": [
        "# Null values if any,\n",
        "print('Number of null Values in Tess data set: ',Tess_df.isna().sum().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGa0sCF0f-IL",
        "outputId": "d9024667-b6d9-4a35-e0cb-c0c4fcbe6bf9"
      },
      "outputs": [],
      "source": [
        "# Dataframe information\n",
        "Tess_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DZOuCrtRlXO",
        "outputId": "39da88f5-5a5b-44d1-f2b9-ba6bd801dd55"
      },
      "outputs": [],
      "source": [
        "# Combining all the datasets into a single pandas series\n",
        "main_df = pd.concat([Crema_df,Ravdess_df,Savee_df,Tess_df],axis=0)\n",
        "main_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "4EFbrQiw4PIG",
        "outputId": "d676752c-fd67-4f4c-faed-4ff73b4d8653"
      },
      "outputs": [],
      "source": [
        "# Concatenated Dataframe contents\n",
        "main_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLmgb_valSEf",
        "outputId": "bc76c66f-6e84-42c6-ec57-e34997a2fb73"
      },
      "outputs": [],
      "source": [
        "# Concatenated Datasets Unique Emotions\n",
        "main_df['Emotion'].unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 382
        },
        "id": "sSpOpBYLPmaR",
        "outputId": "73887171-1576-4106-e8a7-0f8f63c9ba94"
      },
      "outputs": [],
      "source": [
        "# Emotion Distribution\n",
        "plt.figure(figsize=(20,6))\n",
        "plt.title('Emotions Counts in concatenated Dataset')\n",
        "emotions=sns.countplot(x='Emotion',data=main_df,palette='Set3')\n",
        "emotions.set_xticklabels(emotions.get_xticklabels())\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_ewgne6tSJ50",
        "outputId": "0ed032b8-cc7c-4127-8ae9-8f0bd62231a2"
      },
      "outputs": [],
      "source": [
        "# Emotion names\n",
        "emotion_names=main_df['Emotion'].unique()\n",
        "emotion_names"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uKvE6ahCSRBV"
      },
      "outputs": [],
      "source": [
        "# Unique color for each Emotion\n",
        "\n",
        "colors={'disgust':'#808080','happy':'#ffff00','sad':'#ff4000','neutral':'#00bfff','fear':'#ff8000','angry':'#ff0000','surprise':'#ff00ff'}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Oqygo8LXVmL"
      },
      "source": [
        ">Waveplot\n",
        "Plotting the amplitude envelope of a waveform.\n",
        "\n",
        ">Spectrogram\n",
        "A spectrogram is a visual representation of the spectrum of frequencies of a signal as it varies with time. When applied to an audio signal, spectrograms are sometimes called sonographs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bouKULkSZHR"
      },
      "outputs": [],
      "source": [
        "# Function to create waveplots  for the audio files\n",
        "def wave_plot(data,sr,emotion,color):\n",
        "    plt.figure(figsize=(20,6))\n",
        "    plt.title(f'{emotion} emotion for waveplot',size=18)\n",
        "    librosa.display.waveshow(y=data,sr=sr,color=color,label=\"Frequency over time\")\n",
        "    plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i3fTWY02Se-d"
      },
      "outputs": [],
      "source": [
        "# Function to create spectogram for the audio files\n",
        "def spectogram(data,sr,emotion):\n",
        "    audio=librosa.stft(data)\n",
        "    audio_db=librosa.amplitude_to_db(abs(audio))\n",
        "    plt.figure(figsize=(20,6))\n",
        "    plt.title(f'{emotion} emotion for spectogram',size=18)\n",
        "    librosa.display.specshow(audio_db,sr=sr,x_axis='time',y_axis='hz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Jy1aw41VSjay",
        "outputId": "7428600c-a7dc-4abc-8760-adf946d7008c"
      },
      "outputs": [],
      "source": [
        "# Creating feature graphs for the audio files\n",
        "audio_path=[]\n",
        "for emotion in emotion_names:\n",
        "    path=np.array(main_df['File_Path'][main_df['Emotion']==emotion])[1]\n",
        "    data,sr=librosa.load(path)\n",
        "    wave_plot(data,sr,emotion,colors[emotion])\n",
        "    spectogram(data,sr,emotion)\n",
        "    audio_path.append(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Xzcf_yIzEJLj",
        "outputId": "520b7ae5-84c6-4f19-a5d8-b8be0d71ea3a"
      },
      "outputs": [],
      "source": [
        "# Audio sample for disgust emotion\n",
        "print('Disgust Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "IvWkwJEYGMAQ",
        "outputId": "64397ade-1833-4ad0-cb60-3f5bcd117f30"
      },
      "outputs": [],
      "source": [
        "# Audio sample for happy emotion\n",
        "print('Happy Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "GYvP5maPGS-_",
        "outputId": "3e82ebc4-3a84-4677-df71-e1a36071c534"
      },
      "outputs": [],
      "source": [
        "# Audio sample for sad emotion\n",
        "print('Sad Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "32_Kxx4VGd9g",
        "outputId": "1b1a5730-4589-4f4c-e1de-9b63218a17cc"
      },
      "outputs": [],
      "source": [
        "# Audio sample for neutral emotion\n",
        "print('Neutral Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "yZnBILahGhlc",
        "outputId": "79590528-a7fd-409a-b0d2-67a952402fc5"
      },
      "outputs": [],
      "source": [
        "# Audio sample for fear emotion\n",
        "print('Fear Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[4])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "WymUVgprGojt",
        "outputId": "95eab11a-c543-40ec-c52b-1d4bed4e4527"
      },
      "outputs": [],
      "source": [
        "# Audio sample for angry emotion\n",
        "print('Angry Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[5])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "id": "Zt6oXxs_G1c2",
        "outputId": "a40940b2-b4b3-40b3-c070-a83e22e51bae"
      },
      "outputs": [],
      "source": [
        "# Audio sample for surprise emotion\n",
        "print('Surprise Audio Sample\\n\\n')\n",
        "IPython.display.Audio(audio_path[6])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JkMuL5BRViWU"
      },
      "source": [
        "#### Manipulating Audio Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Am2yFo5ASrrX"
      },
      "outputs": [],
      "source": [
        "# Audio files Manipualtion\n",
        "def add_noise(data,random=False,rate=0.035,threshold=0.075):\n",
        "    if random:\n",
        "        rate=np.random.random()*threshold\n",
        "    noise=rate*np.random.uniform()*np.amax(data)\n",
        "    augmented_data=data+noise*np.random.normal(size=data.shape[0])\n",
        "    return augmented_data\n",
        "\n",
        "def shifting(data,rate=1000):\n",
        "    augmented_data=int(np.random.uniform(low=-5,high=5)*rate)\n",
        "    augmented_data=np.roll(data,augmented_data)\n",
        "    return augmented_data\n",
        "\n",
        "def pitching(data,sr,pitch_factor=0.7,random=False):\n",
        "    if random:\n",
        "        pitch_factor=np.random.random() * pitch_factor\n",
        "    return librosa.effects.pitch_shift(data,sr,pitch_factor)\n",
        "\n",
        "def streching(data,rate=0.8):\n",
        "  return librosa.effects.time_stretch(data,rate)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "0gd4TlknnEE6",
        "outputId": "381537fb-aefb-4f10-a032-0f44a003dfdb"
      },
      "outputs": [],
      "source": [
        "# Original Audio Sample\n",
        "print('\\t\\t Original Audio\\n')\n",
        "plt.figure(figsize=(20,6))\n",
        "librosa.display.waveshow(data,sr,color='#8000ff',label=\"Frequency over time\")\n",
        "plt.legend()\n",
        "IPython.display.Audio(audio_path[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "l6UiI41lnJxO",
        "outputId": "6c3f314a-7a42-4c1b-a024-7170b8dbe90e"
      },
      "outputs": [],
      "source": [
        "# Orginal Audio + Noise\n",
        "print('\\t\\t Noise Audio\\n')\n",
        "noised_audio=add_noise(data)\n",
        "plt.figure(figsize=(20,6))\n",
        "librosa.display.waveshow(noised_audio,sr,color='#8000ff',label=\"Frequency over time\")\n",
        "plt.legend()\n",
        "IPython.display.Audio(noised_audio,rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "id": "GPXksZZnnn0e",
        "outputId": "7884e922-60b8-42cb-86f0-0d8049ae36de"
      },
      "outputs": [],
      "source": [
        "# Orginal Audio + Streched\n",
        "print('\\t\\t Streched Audio\\n')\n",
        "stretched_audio=streching(data)\n",
        "plt.figure(figsize=(20,6))\n",
        "librosa.display.waveshow(stretched_audio,sr,color='#8000ff',label=\"Frequency over time\")\n",
        "plt.legend()\n",
        "IPython.display.Audio(stretched_audio,rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "KeqpPe67nw_Z",
        "outputId": "e176a5f2-58a4-4ded-d72b-5dfe0e08280a"
      },
      "outputs": [],
      "source": [
        "# Orginal Audio + Shifted\n",
        "print('\\t\\t Shifted Audio\\n')\n",
        "shifted_audio=shifting(data)\n",
        "plt.figure(figsize=(20,6))\n",
        "librosa.display.waveshow(shifted_audio,sr,color='#8000ff',label=\"Frequency over time\")\n",
        "plt.legend()\n",
        "IPython.display.Audio(shifted_audio,rate=sr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 463
        },
        "id": "9XJotstln5aW",
        "outputId": "45f97948-1fd0-4847-a796-e7d60ee10231"
      },
      "outputs": [],
      "source": [
        "# Orginal Audio + Pitch\n",
        "print('\\t\\t Pitched Audio\\n')\n",
        "pitched_audio=pitching(data,sr)\n",
        "plt.figure(figsize=(20,6))\n",
        "librosa.display.waveshow(pitched_audio,sr,color='#8000ff',label=\"Frequency over time\")\n",
        "plt.legend()\n",
        "IPython.display.Audio(pitched_audio,rate=sr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yb0opohGVbLc"
      },
      "source": [
        "> Mel-Frequency Cepstral Coefficients (MFCCs)\n",
        "\n",
        "Mel-Frequency Cepstral Coefficients is a representation of the short-term power spectrum of a sound, based on some transformation in a Mel-scale. It is commonly used in speech recognition as people’s voices are usually on a certain range of frequency and different from one to another. \n",
        "\n",
        "> Root-mean-square (RMS)\n",
        "\n",
        "The root-mean-square here refers to the total magnitude of the signal, which in layman terms can be interpreted as the loudness or energy parameter of the audio file.\n",
        "\n",
        "\n",
        "\n",
        "> Zero crossing rate (ZCR)\n",
        "\n",
        "zero-crossing rate is the rate at which a signal changes from positive to zero to negative or from negative to zero to positive. Its value has been widely used in both speech recognition and music information retrieval, being a key feature to classify percussive sounds. Highly percussive sounds like rock, metal, emo, or punk music tend to have higher zero-crossing rate values.\n",
        "\n",
        "\n",
        "> Tonnetz\n",
        "\n",
        "Tonnetz (German for 'tone network') is a conceptual lattice diagram representing tonal space. Various visual representations of the Tonnetz can be used to show traditional harmonic relationships "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lyWQFu2OTfPh"
      },
      "outputs": [],
      "source": [
        "# Audio files features extraction\n",
        "def zcr(data):\n",
        "    zcr=librosa.feature.zero_crossing_rate(data,frame_length=2048,hop_length=512)\n",
        "    return np.array(np.squeeze(zcr))\n",
        "def rms(data):\n",
        "    rms=librosa.feature.rms(data,frame_length=2048,hop_length=512)\n",
        "    return np.array(np.squeeze(rms))\n",
        "def tonnetz(data,sr):\n",
        "    tonnetz=librosa.feature.tonnetz(data,sr=sr)\n",
        "    return np.array(np.ravel(tonnetz))\n",
        "def mfcc(data,sr):\n",
        "    mfcc=librosa.feature.mfcc(data,sr=sr)\n",
        "    return np.array(np.ravel(mfcc.T))\n",
        "\n",
        "\n",
        "#function to get features from MFCC, ZCR, RMS and Tonnetz\n",
        "def extract_features(data,sr):\n",
        "\n",
        "    result=np.array([])\n",
        "    result = np.append(result,mfcc(data,sr))\n",
        "    result = np.append(result,tonnetz(data,sr))\n",
        "    result = np.append(result, rms(data))\n",
        "    result = np.append(result, zcr(data))\n",
        " \n",
        "    return result\n",
        "\n",
        "# Function to extract features from individual audio path\n",
        "def get_features(path,duration=2.5, offset=0.6):\n",
        "    data,sr=librosa.load(path,duration=duration,offset=offset)\n",
        "    aud=extract_features(data,sr)\n",
        "    \n",
        "    return aud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_XCZ2G0lbe5",
        "outputId": "433d60cd-6873-47c3-86d0-360aeef3d6e2"
      },
      "outputs": [],
      "source": [
        "# Data preparation for testing and training\n",
        "X,Y=[],[]\n",
        "for path,emotion,index in zip(main_df.File_Path,main_df.Emotion,range(main_df.File_Path.shape[0])):\n",
        "    features=get_features(path)\n",
        "    X.append(features)\n",
        "    Y.append(emotion)\n",
        "    if (index == main_df.File_Path.shape[0] -1):\n",
        "      print('Features from all the audio files are extracted')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CpSpkKOgbbYp"
      },
      "outputs": [],
      "source": [
        "# Features extracted file from all the datasets\n",
        "processed_data_path= 'Processed_Data.csv'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i7_v4_V0grSo"
      },
      "outputs": [],
      "source": [
        "# Converting X and Y arrays to CSV file and to be saved in specified path above\n",
        "extract=pd.DataFrame(X)\n",
        "extract['Emotion']=Y\n",
        "extract.to_csv(processed_data_path,index=False)\n",
        "extract.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSGQ7QksbhWO",
        "outputId": "42d364c1-a662-418e-b557-cfddb78447d0"
      },
      "outputs": [],
      "source": [
        "# Converting features sile to dataframe\n",
        "df=pd.read_csv(processed_data_path)\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "HaLvXtN_pvxO",
        "outputId": "11635719-1d91-4cb1-8f8e-6d475b99b779"
      },
      "outputs": [],
      "source": [
        "# Contents of dataframe\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eeLSrro_blL-",
        "outputId": "f71bfeb2-204a-4761-809d-e433a4e759a4"
      },
      "outputs": [],
      "source": [
        "# Removing all the null values and replacing with 0\n",
        "df=df.fillna(0)\n",
        "print('Number of null Values in data set: ',df.isna().sum().sum())\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0QFuH8D9gyVI",
        "outputId": "c51fc640-5936-4571-9fba-544367cd71a2"
      },
      "outputs": [],
      "source": [
        "# Processed dataframe information\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6d2fbizjn6X"
      },
      "outputs": [],
      "source": [
        "# Creating X and Y variables for train and test split\n",
        "X=df.drop(labels='Emotion',axis=1)\n",
        "Y=df['Emotion']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICDPM2Ryogl-",
        "outputId": "fb523c70-0857-4760-e60b-2d29b4c86119"
      },
      "outputs": [],
      "source": [
        "# Train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.4, random_state=1, stratify = Y,shuffle=True)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFYXKHURVT-X"
      },
      "outputs": [],
      "source": [
        "# Accuracy of different models\n",
        "models_accuracy_scores = []\n",
        "model_names = ['SVC', 'SVC Tuned', 'MLPC', 'MLPC Tuned','KNN', 'KNN_Tuned','Decision Tree', 'Decision Tree Tuned', 'LR', 'LR Tuned', 'CNN', 'CNN Tuned']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8R2BNVZmdUdk"
      },
      "outputs": [],
      "source": [
        "# Importing all the trained models\n",
        "SVC_model = joblib.load(r'models/finalized_SVC_model.sav')\n",
        "SVC_tuned_model = joblib.load(r'models/finalized_SVC_tuned_model.sav')   \n",
        "\n",
        "MLPC_model = joblib.load(r'models/finalized_MLPC_model.sav')\n",
        "MLPC_tuned_model = joblib.load(r'models/finalized_tuned_MLPC_model.sav')\n",
        "\n",
        "KNN_model = joblib.load(r'models/finalized_KNN_model.sav')\n",
        "KNN_tuned_model = joblib.load(r'models/finalized_KNN_tuned_model.sav')\n",
        "\n",
        "Decision_Tree_model = joblib.load(r'models/finalized_DTC_model.sav')\n",
        "Decision_Tree_tuned_model = joblib.load(r'models/finalized_DTC_tuned_model.sav')\n",
        "\n",
        "Logistic_Regression_model = joblib.load(r'models/finalized_LR_model.sav')\n",
        "Logistic_Regression_tuned_model = joblib.load(r'models/finalized_DTC_tuned_model.sav')\n",
        "\n",
        "CNN_model = tf.keras.models.load_model(r'models/finalized_CNN_model.h5')\n",
        "CNN_tuned_model = tf.keras.models.load_model(r'models/finalized_CNN_tuned_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bXPNriCeu6tp"
      },
      "outputs": [],
      "source": [
        "# Intinalizing scalar and fiting train and test data\n",
        "scaler=StandardScaler()\n",
        "\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "\n",
        "X_test=scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bDAxRCsiu6MB"
      },
      "outputs": [],
      "source": [
        "# Predictions from SVC and MLPC models\n",
        "y_pred1 = SVC_model.predict(X_test)\n",
        "y_pred2 = SVC_tuned_model.predict(X_test) \n",
        "\n",
        "y_pred3 = MLPC_model.predict(X_test)\n",
        "y_pred4 = MLPC_tuned_model.predict(X_test)\n",
        "\n",
        "y_pred5 = KNN_model.predict(X_test)\n",
        "y_pred6 = KNN_tuned_model.predict(X_test)\n",
        "\n",
        "y_pred7 = Decision_Tree_model.predict(X_test)\n",
        "y_pred8 = Decision_Tree_tuned_model.predict(X_test)\n",
        "\n",
        "y_pred9 = Logistic_Regression_model.predict(X_test)\n",
        "y_pred10 = Logistic_Regression_tuned_model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G51zpQ1CMqwe",
        "outputId": "8fef3a19-86de-4722-ff62-108e3635f12a"
      },
      "outputs": [],
      "source": [
        "# Classification report of SVC models\n",
        "print(f'\\t  SVC Model Classification Report\\n\\n',classification_report(y_test,y_pred1,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')\n",
        "print(f'\\t SVC tuned Model Classification Report\\n\\n',classification_report(y_test,y_pred2,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RdgcGB5NheAw",
        "outputId": "65debd63-ae1c-4f05-a58c-32325e22356b"
      },
      "outputs": [],
      "source": [
        "# Classification report of  MLPC models\n",
        "print(f'\\t  MLPC Model Classification Report\\n\\n',classification_report(y_test,y_pred3,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')\n",
        "print(f'\\t MLPC  tuned Model Classification Report\\n\\n',classification_report(y_test,y_pred4,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e_fhEhEPhdxq",
        "outputId": "2e8f7c6c-699f-47c0-d52e-addd64451ca8"
      },
      "outputs": [],
      "source": [
        "# Classification report of  KNN models\n",
        "print(f'\\t  KNN Model Classification Report\\n\\n',classification_report(y_test,y_pred5,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')\n",
        "print(f'\\t KNN  tuned Model Classification Report\\n\\n',classification_report(y_test,y_pred6,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eRDbHEfbh6Pr",
        "outputId": "c7df42ea-58a3-4c06-e981-c30847c84c11"
      },
      "outputs": [],
      "source": [
        "# Classification report of  DTC models\n",
        "print(f'\\t  Decision Tree Model Classification Report\\n\\n',classification_report(y_test,y_pred7,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')\n",
        "print(f'\\t Decision Tree  tuned Model Classification Report\\n\\n',classification_report(y_test,y_pred8,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5TKPrv2viEkr",
        "outputId": "259100ea-8ad9-4465-95fc-5db5976830e6"
      },
      "outputs": [],
      "source": [
        "# Classification report of  LR models\n",
        "print(f'\\t  Logistic Regression Model Classification Report\\n\\n',classification_report(y_test,y_pred9,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')\n",
        "print(f'\\t Logistic Regression  tuned Model Classification Report\\n\\n',classification_report(y_test,y_pred10,target_names=emotion_names))\n",
        "print('----------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r09vT1CplFEN",
        "outputId": "6c722108-61a8-4cb3-ba1e-946e6c6caa78"
      },
      "outputs": [],
      "source": [
        "# Accuracy of SVC model\n",
        "accuracy=accuracy_score(y_pred1,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of SVC Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RssTkTnNlBNO",
        "outputId": "4951ea8a-42fa-4664-b468-b484d07d3aba"
      },
      "outputs": [],
      "source": [
        "# Accuracy of SVC tuned model\n",
        "accuracy=accuracy_score(y_pred2,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of SVC Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q7VLVHejVPZt",
        "outputId": "0bd43794-ecaf-4c40-87d1-e833f8a93f9a"
      },
      "outputs": [],
      "source": [
        "# Accuracy of MLPC model\n",
        "accuracy=accuracy_score(y_pred3,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of MLPC Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k8CW20t3VQDL",
        "outputId": "18569ea3-992d-4010-f2f4-da343ea98501"
      },
      "outputs": [],
      "source": [
        "# Accuracy of MLPC tuned model\n",
        "accuracy=accuracy_score(y_pred4,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of MLPC Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OKW7iNujiaJ2",
        "outputId": "b623047d-cc2e-4fec-cd52-e479d001b614"
      },
      "outputs": [],
      "source": [
        "# Accuracy of KNN model\n",
        "accuracy=accuracy_score(y_pred5,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of KNN Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHxmovwGijXy",
        "outputId": "be5d6004-ee89-4b81-a35b-a6631b19424b"
      },
      "outputs": [],
      "source": [
        "# Accuracy of KNN model\n",
        "accuracy=accuracy_score(y_pred6,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of KNN Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zn-BNXgfinZk",
        "outputId": "4608ecd7-5368-4b9b-cf26-e95a23620540"
      },
      "outputs": [],
      "source": [
        "# Accuracy of DTC model\n",
        "accuracy=accuracy_score(y_pred7,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of Decision Tree Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yTfRAYLrisF_",
        "outputId": "192b303a-85c9-4996-94ef-2aa9a9b6e0fd"
      },
      "outputs": [],
      "source": [
        "# Accuracy of DTC Tuned model\n",
        "accuracy=accuracy_score(y_pred8,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of Decision Tree Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ngvyt1qi2Sh",
        "outputId": "059f71da-579b-4b5c-ca99-f0ab0c208986"
      },
      "outputs": [],
      "source": [
        "# Accuracy of LR model\n",
        "accuracy=accuracy_score(y_pred9,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of LR Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "65WCYegIi6cM",
        "outputId": "a9f5d999-eba3-4db3-eb8f-b25ccc4b1443"
      },
      "outputs": [],
      "source": [
        "# Accuracy of LR Tuned model\n",
        "accuracy=accuracy_score(y_pred10,y_test)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of LR Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "BurZIcjpNUA0",
        "outputId": "9cb80fe6-2b38-4b3b-935a-ad59813070e9"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of SVC\n",
        "conf=confusion_matrix(y_test,y_pred1)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for SVC model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "kKwOjEeuNhbG",
        "outputId": "73876288-79cf-4d63-bf90-d5165b80a641"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of SVC tuned model\n",
        "conf=confusion_matrix(y_test,y_pred2)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for SVC tuned model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "AyH65Md-NmYV",
        "outputId": "11d86637-d846-4ee6-b002-2212418de120"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of MLPC model\n",
        "conf=confusion_matrix(y_test,y_pred3)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for MLPC model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "aA-WXDaiNsZV",
        "outputId": "737aa920-4fb1-46d4-ebde-0009bb73d768"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of MLPC tuned model\n",
        "conf=confusion_matrix(y_test,y_pred4)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for MLPC model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "6Qr4aq-SjHCe",
        "outputId": "d59ac2ee-c5cb-41d0-8fc3-6c729aecadd8"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of KNN model\n",
        "conf=confusion_matrix(y_test,y_pred5)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for KNN model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "e6tQHlS6jNp7",
        "outputId": "d89a0d57-fa72-43f3-88b6-890c91276fcc"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of KNN Tuned model\n",
        "conf=confusion_matrix(y_test,y_pred6)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for KNN Tuned model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "eQm_7fOBjUHo",
        "outputId": "6392f781-88e4-45f8-9628-c566579240c4"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of DTC model\n",
        "conf=confusion_matrix(y_test,y_pred7)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for Decision Tree classifier model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "PsHSIFGmjawr",
        "outputId": "c59367c8-5adf-4b92-f215-b3ed8e745370"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of DTC Tuned model\n",
        "conf=confusion_matrix(y_test,y_pred8)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for Decision Tree classifier Tuned  model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "7axlCfJRjkP7",
        "outputId": "e63e53df-6b21-4180-be96-94c9db662fea"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of LR model\n",
        "conf=confusion_matrix(y_test,y_pred9)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for Logistic Regression model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ER34oDyBjr6x",
        "outputId": "674c7225-05bf-496d-a763-4fed0d03b4a5"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of LR Tuned model\n",
        "conf=confusion_matrix(y_test,y_pred10)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for Logistic Regression Tuned model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBkKyJw-joh0",
        "outputId": "6fe915cb-f029-4cf0-b4ce-a3681bbf704c"
      },
      "outputs": [],
      "source": [
        "# Label encoder for emotion classes\n",
        "lb=LabelEncoder()\n",
        "Y1=np_utils.to_categorical(lb.fit_transform(Y))\n",
        "print(lb.classes_)\n",
        "Y1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WO_dfZPuubhy",
        "outputId": "30ba335c-9885-47cd-d1e5-84a77d8b1480"
      },
      "outputs": [],
      "source": [
        "# Splitting data for training and testing\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y1, test_size=0.7, random_state=1, stratify = Y,shuffle=True)\n",
        "X_train.shape,X_test.shape,y_train.shape,y_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BJ7ztzVz3asd"
      },
      "outputs": [],
      "source": [
        "# Scalar initalization for train and test data\n",
        "scaler=StandardScaler()\n",
        "\n",
        "X_train=scaler.fit_transform(X_train)\n",
        "\n",
        "X_test=scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1rnW5LUqZt5",
        "outputId": "84e82a13-1ae7-46de-cb29-772cf20c4f99"
      },
      "outputs": [],
      "source": [
        "y_pred11= CNN_model.predict(X_test)\n",
        "cnn_pred = []\n",
        "for i in y_pred11:\n",
        "  j = np.argmax(i)\n",
        "  cnn_pred.append(j)\n",
        "cnn_pred = np.array(cnn_pred)\n",
        "cnn_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mymW4NBHOJ8u",
        "outputId": "cb35da53-a8c2-4c9b-c02d-428b8e10db46"
      },
      "outputs": [],
      "source": [
        "# predictions from CNN tuned model\n",
        "y_pred12= CNN_tuned_model.predict(X_test)\n",
        "CNN_tuned_model_pred = []\n",
        "for i in y_pred12:\n",
        "  j = np.argmax(i)\n",
        "  CNN_tuned_model_pred.append(j)\n",
        "CNN_tuned_model_pred = np.array(CNN_tuned_model_pred)\n",
        "CNN_tuned_model_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7DH71EFwN-ea",
        "outputId": "1a7911b9-9cab-4328-8592-feaee68712ac"
      },
      "outputs": [],
      "source": [
        "# Preparing y_check from y_test for comparision purpose\n",
        "y_check=np.argmax(y_test,axis=1)\n",
        "y_check"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UQFAh9ZLkbOQ",
        "outputId": "3b29ce01-4d1e-440e-f77b-fd9a5deaf969"
      },
      "outputs": [],
      "source": [
        "# Classification report of CNN model\n",
        "print(f'CNN Model Classification Report: \\n\\n',classification_report(y_check,cnn_pred,target_names=emotion_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umbyP8wxkjIb",
        "outputId": "9c9fd02c-afa5-4fa6-99b7-c1123eff926c"
      },
      "outputs": [],
      "source": [
        "# Classification report of CNN tuned model\n",
        "print(f'CNN Tuned Model Classification Report:\\n\\n',classification_report(y_check,CNN_tuned_model_pred,target_names=emotion_names))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WUg1s7aOdyi"
      },
      "outputs": [],
      "source": [
        "# Importing history of CNN and CNN tuned models\n",
        "df1 = pd.read_csv(r'/CNN Models Training History/history1.csv')\n",
        "df2 = pd.read_csv(r'CNN Models Training History/history2.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "PNiJDQeFk1v3",
        "outputId": "1260cde4-1c99-4c17-c68e-011cb77912d2"
      },
      "outputs": [],
      "source": [
        "# Traininng accuracy for CNN model\n",
        "fig=px.line(df1, y=['accuracy','val_accuracy'],\n",
        "           labels={'index':'epoch','value':'accuracy'},\n",
        "           title=f'Trarining and Validation Accuracy Chart for CNN model')\n",
        "plt.figure(figsize=(20,6))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "zOYko-SHk8X7",
        "outputId": "d3c65120-e450-4412-f293-7b2298cf8bc2"
      },
      "outputs": [],
      "source": [
        "# Training loss for CNN model\n",
        "fig=px.line(df1, y=['loss','val_loss'],\n",
        "           labels={'index':'epoch','value':'loss'},\n",
        "           title=f'Training and Validation Loss Chart for CNN model')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        },
        "id": "QZgJP0Z9_3XT",
        "outputId": "5d398d54-dcbb-47f7-e988-8d42155068d7"
      },
      "outputs": [],
      "source": [
        "# Training accuracy for CNN tuned model\n",
        "fig=px.line(df2, y=['accuracy','val_accuracy'],\n",
        "           labels={'index':'epoch','value':'accuracy'},\n",
        "           title=f'Trarining and Validation Accuracy Chart of CNN tuned model')\n",
        "plt.figure(figsize=(20,6))\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "cfan4nqGAY-0",
        "outputId": "99f76e08-e123-4946-8157-211fa0c7e371"
      },
      "outputs": [],
      "source": [
        "# Training loss for CNN tuned model\n",
        "fig=px.line(df1, y=['loss','val_loss'],\n",
        "           labels={'index':'epoch','value':'loss'},\n",
        "           title=f'Training and Validation Loss Chart of CNN tuned model')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VT-dBirSVRRP",
        "outputId": "9eb28c18-5b64-4667-e9d1-82223d6b7d2c"
      },
      "outputs": [],
      "source": [
        "#Accuracy score for CNN model\n",
        "accuracy=accuracy_score(cnn_pred,y_check)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of CNN  Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZdL3qgxGRpz",
        "outputId": "dd7adb07-6c6b-44a1-d9c2-b024242994a2"
      },
      "outputs": [],
      "source": [
        "# Accuracy score for CNN tuned model\n",
        "accuracy=accuracy_score(CNN_tuned_model_pred,y_check)\n",
        "models_accuracy_scores.append(accuracy)\n",
        "print(f'Accuracy Score of CNN Tuned Model: {accuracy}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "6rUrQgwvlH4G",
        "outputId": "c5eed491-08f6-45f2-f2a1-f9c7019a24bf"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of CNN model\n",
        "conf=confusion_matrix(y_check,cnn_pred)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for CNN model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "ioix4Cr-QQgq",
        "outputId": "805eccae-7553-41b3-de24-203b923a40d0"
      },
      "outputs": [],
      "source": [
        "# Confusion matrix of CNN tuned model\n",
        "conf=confusion_matrix(y_check,CNN_tuned_model_pred)\n",
        "cm=pd.DataFrame(\n",
        "    conf,index=[i for i in emotion_names],\n",
        "    columns=[i for i in emotion_names]\n",
        ")\n",
        "plt.figure(figsize=(20,6))\n",
        "ax=sns.heatmap(cm,annot=True,fmt='d')\n",
        "ax.set_title(f'confusion matrix for CNN Tuned model ')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 386
        },
        "id": "tfpe-_RYJuew",
        "outputId": "d7e36cc3-fe5d-4a09-c70a-3f16e451b818"
      },
      "outputs": [],
      "source": [
        "# Models vs accuracy chart\n",
        "def addlabels(x,y):\n",
        "\tfor i in range(len(x)):\n",
        "\t\tplt.text(i, y[i]+0.02, round(y[i],3), ha = 'center')\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\tplt.figure(figsize = (20,6))\n",
        "\tplt.bar(model_names, models_accuracy_scores)\n",
        "\taddlabels(model_names, models_accuracy_scores)\n",
        "\tplt.title(\"Models Vs Accuracy\")\n",
        "\tplt.xlabel(\"Models\")\n",
        "\tplt.ylabel(\"Accuracy Scores\")\n",
        "\tplt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8BgKHcC2NYzB"
      },
      "source": [
        "Conclusion:\n",
        "\n",
        "From the above analysis we can draw the following statements.\n",
        "1. Detecting emotion from audio instead of speech is critically useful when the same audio content is expressed in different emotions.\n",
        "2. Features for audio mainly depends on tone, rythm, pitch, frequency, amplitude, speed of sound, etc.\n",
        "3. Advanced Audio features like MFCC, RMS, ZCR, Tonnetz provides data about the audio that is unique and helps the machine learning models to take advantage of the audio file and predict an emotion.\n",
        "4. Different Audio manipulation techniques can also be used for model learning which makes the audio more clearer, louder and enhance time parameters like shifting, stretching etc.\n",
        "5. Machine learning models used for this project are modeled in two version one, base models and two, parameter tuned models. Base models outperformed tuned models in some cases while tuned models take strong grip in neural network models.\n",
        "6. Through perfomance analysis of models, accuracy score greater than 80% are recommended for real world scenarios in predictions."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
